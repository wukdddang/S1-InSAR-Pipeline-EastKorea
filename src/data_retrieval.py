"""
Sentinel-1 Data Retrieval Module
ASF (Alaska Satellite Facility)ë¥¼ í†µí•œ Sentinel-1 ë°ì´í„° ê²€ìƒ‰ ë° ë‹¤ìš´ë¡œë“œ
"""

import os
from pathlib import Path
from datetime import datetime
from typing import List, Dict
import logging

try:
    import asf_search as asf
except ImportError:
    print("âš ï¸ asf-search íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("ì„¤ì¹˜ ëª…ë ¹: pip install asf-search")
    asf = None

from shapely.geometry import box
import pandas as pd
from rich.console import Console
from rich.table import Table

from .config import get_config

console = Console()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class Sentinel1Retriever:
    """Sentinel-1 ë°ì´í„° ê²€ìƒ‰ ë° ë‹¤ìš´ë¡œë“œ í´ë˜ìŠ¤ (ASF Data Search ì‚¬ìš©)"""
    
    def __init__(self, config_path: str = None):
        """
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        if asf is None:
            raise ImportError(
                "asf-search íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n"
                "ì„¤ì¹˜: pip install asf-search"
            )
        
        self.config = get_config(config_path)
        self.session = None
        self._init_session()
    
    def _init_session(self):
        """ASF ì„¸ì…˜ ì´ˆê¸°í™”"""
        credentials = self.config.get_credential('asf')
        
        if not credentials or not credentials.get('username'):
            logger.warning("ASF ì¸ì¦ ì •ë³´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            logger.warning("credentials.yaml íŒŒì¼ì„ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            logger.info("ê²€ìƒ‰ì€ ê°€ëŠ¥í•˜ì§€ë§Œ, ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•´ì„œëŠ” ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            self.session = None
            return
        
        try:
            # í™˜ê²½ ë³€ìˆ˜ë¡œ ì¸ì¦ ì •ë³´ ì„¤ì • (asf-searchê°€ ìë™ìœ¼ë¡œ ì‚¬ìš©)
            os.environ['EARTHDATA_USERNAME'] = credentials['username']
            os.environ['EARTHDATA_PASSWORD'] = credentials['password']
            
            # ASF ì„¸ì…˜ ìƒì„±
            self.session = asf.ASFSession()
            logger.info("ASF ì„¸ì…˜ ì´ˆê¸°í™” ì„±ê³µ (í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©)")
        except Exception as e:
            logger.error(f"ASF ì„¸ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.info("ê²€ìƒ‰ì€ ê³„ì† ì§„í–‰í•˜ì§€ë§Œ, ë‹¤ìš´ë¡œë“œëŠ” ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            self.session = None
    
    def get_aoi_wkt(self) -> str:
        """ë¶„ì„ ì˜ì—­(AOI) WKT ìƒì„±"""
        aoi_config = self.config.get('aoi')
        bbox = box(
            aoi_config['min_lon'],
            aoi_config['min_lat'],
            aoi_config['max_lon'],
            aoi_config['max_lat']
        )
        return str(bbox)
    
    def search_products(
        self,
        start_date: str = None,
        end_date: str = None,
        max_results: int = 100
    ) -> pd.DataFrame:
        """Sentinel-1 ì œí’ˆ ê²€ìƒ‰
        
        Args:
            start_date: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
            end_date: ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)
            max_results: ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
        
        Returns:
            ê²€ìƒ‰ëœ ì œí’ˆ ì •ë³´ DataFrame
        """
        # ë‚ ì§œ ì„¤ì •
        if start_date is None:
            start_date = self.config.get('sentinel1', 'date_range', 'start')
        if end_date is None:
            end_date = self.config.get('sentinel1', 'date_range', 'end')
        
        # ê²€ìƒ‰ ì˜ì—­
        aoi_wkt = self.get_aoi_wkt()
        
        logger.info(f"ê²€ìƒ‰ ì¤‘: {start_date} ~ {end_date}")
        logger.info(f"ì˜ì—­: {self.config.get('aoi', 'name')}")
        
        try:
            # ASF ê²€ìƒ‰ (orbit direction ì œì™¸í•˜ì—¬ ë” ë§ì€ ê²°ê³¼ ê²€ìƒ‰)
            results = asf.search(
                platform=asf.PLATFORM.SENTINEL1,
                processingLevel=asf.PRODUCT_TYPE.SLC,
                beamMode=asf.BEAMMODE.IW,
                # flightDirection ì œê±° - ASCENDINGê³¼ DESCENDING ëª¨ë‘ ê²€ìƒ‰
                start=start_date,
                end=end_date,
                intersectsWith=aoi_wkt,
                maxResults=max_results
            )
            
            logger.info(f"ê²€ìƒ‰ ì¡°ê±´: Sentinel-1 SLC, IW ëª¨ë“œ, ëª¨ë“  ê¶¤ë„ ë°©í–¥")
            
            logger.info(f"ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ì œí’ˆ ë°œê²¬")
            
            # DataFrameìœ¼ë¡œ ë³€í™˜
            products_data = []
            for result in results:
                path_value = result.properties.get('pathNumber')
                
                # orbitì€ absolute orbit numberì´ë¯€ë¡œ relative orbit (track)ìœ¼ë¡œ ë³€í™˜
                # Sentinel-1ì˜ relative orbit numberëŠ” 1-175 ë²”ìœ„
                absolute_orbit = result.properties.get('orbit')
                if absolute_orbit is not None:
                    track_value = ((absolute_orbit - 1) % 175) + 1
                else:
                    track_value = 'N/A'
                
                products_data.append({
                    'title': result.properties['sceneName'],
                    'date': result.properties['startTime'],
                    'path': path_value if path_value is not None else 'N/A',
                    'track': track_value,
                    'size_mb': result.properties.get('bytes', 0) / (1024**2),
                    'url': result.properties.get('url', ''),
                    'product': result
                })
            
            return pd.DataFrame(products_data)
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def search_image_pair(
        self,
        start_date: str = '2023-01-01',
        end_date: str = '2023-12-31',
        temporal_baseline_days: int = 12,
        max_results: int = 100
    ) -> pd.DataFrame:
        """
        InSARìš© ì˜ìƒ ìŒ ê²€ìƒ‰ (ê°™ì€ í”„ë ˆì„, ì§€ì •ëœ ì‹œê°„ ê°„ê²©)
        
        Parameters:
        - start_date: ì‹œì‘ ë‚ ì§œ
        - end_date: ì¢…ë£Œ ë‚ ì§œ
        - temporal_baseline_days: ì˜ìƒ ê°„ ì‹œê°„ ê°„ê²© (ì¼)
        - max_results: ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
        
        Returns:
        - products_df: 2ê°œì˜ ì˜ìƒ ì •ë³´ DataFrame
        """
        from datetime import datetime, timedelta
        
        logger.info(f"InSAR ì˜ìƒ ìŒ ê²€ìƒ‰ ì‹œì‘ (ê°„ê²©: {temporal_baseline_days}ì¼)")
        
        # 1. ì „ì²´ ê¸°ê°„ ê²€ìƒ‰
        all_products_df = self.search_products(
            start_date=start_date,
            end_date=end_date,
            max_results=max_results
        )
        
        if all_products_df.empty:
            logger.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame()
        
        # 2. ë‚ ì§œì™€ ì‹œê°„ìœ¼ë¡œ ê·¸ë£¹í™” (ê°™ì€ í”„ë ˆì„ = ë¹„ìŠ·í•œ ì‹œê°„)
        all_products_df['datetime'] = pd.to_datetime(all_products_df['date'])
        all_products_df['time_only'] = all_products_df['datetime'].dt.time
        all_products_df['date_only'] = all_products_df['datetime'].dt.date
        
        # 3. ì‹œê°„ëŒ€ë³„ë¡œ ê·¸ë£¹í™” (ê°™ì€ í”„ë ˆì„ ì°¾ê¸°)
        # ì‹œê°„ì„ ë¶„ ë‹¨ìœ„ë¡œ ë°˜ì˜¬ë¦¼í•´ì„œ ê°™ì€ í”„ë ˆì„ ë¬¶ê¸°
        all_products_df['time_minute'] = all_products_df['datetime'].dt.floor('1min')
        
        # 4. ê°€ì¥ ë§ì€ ì˜ìƒì´ ìˆëŠ” ì‹œê°„ëŒ€(í”„ë ˆì„) ì°¾ê¸°
        time_groups = all_products_df.groupby(all_products_df['time_minute'].dt.time)
        most_common_time = time_groups.size().idxmax()
        
        logger.info(f"ê°€ì¥ ë§ì€ ì˜ìƒì´ ìˆëŠ” ì´¬ì˜ ì‹œê°„: {most_common_time}")
        
        # 5. í•´ë‹¹ ì‹œê°„ëŒ€ì˜ ì˜ìƒë§Œ í•„í„°ë§
        same_frame_df = all_products_df[
            all_products_df['time_minute'].dt.time == most_common_time
        ].copy()
        
        if len(same_frame_df) < 2:
            logger.warning(f"ê°™ì€ í”„ë ˆì„ì˜ ì˜ìƒì´ {len(same_frame_df)}ê°œë¿ì…ë‹ˆë‹¤")
            return same_frame_df
        
        # 6. ë‚ ì§œìˆœ ì •ë ¬
        same_frame_df = same_frame_df.sort_values('datetime').reset_index(drop=True)
        
        # 7. íŒŒì¼ í¬ê¸°ë¡œ burst ìˆ˜ ì¶”ì • (í¬ê¸°ê°€ ë¹„ìŠ· = ë¹„ìŠ·í•œ ì»¤ë²„ë¦¬ì§€)
        # í¬ê¸°ê°€ ë„ˆë¬´ ì‘ê±°ë‚˜ í° ì˜ìƒ ì œì™¸ (median ëŒ€ë¹„ 50% ì´ìƒ ì°¨ì´ë‚˜ë©´ ì œì™¸)
        median_size = same_frame_df['size_mb'].median()
        min_size = median_size * 0.5
        max_size = median_size * 1.5
        
        filtered_df = same_frame_df[
            (same_frame_df['size_mb'] >= min_size) & 
            (same_frame_df['size_mb'] <= max_size)
        ].copy()
        
        logger.info(f"í¬ê¸° í•„í„°ë§: {len(same_frame_df)}ê°œ â†’ {len(filtered_df)}ê°œ")
        logger.info(f"í¬ê¸° ë²”ìœ„: {min_size:.0f} - {max_size:.0f} MB (median: {median_size:.0f} MB)")
        
        if len(filtered_df) < 2:
            logger.warning("í¬ê¸°ê°€ ë¹„ìŠ·í•œ ì˜ìƒì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í•„í„°ë§í•˜ì§€ ì•Šê³  ì§„í–‰í•©ë‹ˆë‹¤.")
            filtered_df = same_frame_df
        
        # 8. ì§€ì •ëœ ì‹œê°„ ê°„ê²©ì— ê°€ì¥ ê°€ê¹Œìš´ ìŒ ì°¾ê¸°
        target_delta = timedelta(days=temporal_baseline_days)
        best_pair = None
        min_diff = timedelta(days=9999)
        
        for i in range(len(filtered_df) - 1):
            for j in range(i + 1, len(filtered_df)):
                date1 = filtered_df.iloc[i]['datetime']
                date2 = filtered_df.iloc[j]['datetime']
                actual_delta = date2 - date1
                diff = abs(actual_delta - target_delta)
                
                if diff < min_diff:
                    min_diff = diff
                    best_pair = (filtered_df.index[i], filtered_df.index[j])
                    actual_baseline = actual_delta.days
        
        if best_pair:
            i, j = best_pair
            pair_df = same_frame_df.loc[[i, j]].reset_index(drop=True)
            
            logger.info(f"âœ“ ì˜ìƒ ìŒ ë°œê²¬!")
            logger.info(f"  Reference: {pair_df.iloc[0]['date']} ({pair_df.iloc[0]['size_mb']:.0f} MB)")
            logger.info(f"  Secondary: {pair_df.iloc[1]['date']} ({pair_df.iloc[1]['size_mb']:.0f} MB)")
            logger.info(f"  Temporal Baseline: {actual_baseline}ì¼")
            logger.info(f"  ì´¬ì˜ ì‹œê°„: {most_common_time}")
            logger.info(f"  í¬ê¸° ì°¨ì´: {abs(pair_df.iloc[0]['size_mb'] - pair_df.iloc[1]['size_mb']):.0f} MB")
            
            # ì •ë¦¬ëœ ì—´ë§Œ ë°˜í™˜
            return pair_df[['title', 'date', 'path', 'track', 'size_mb', 'url', 'product']]
        else:
            logger.warning("ì ì ˆí•œ ì˜ìƒ ìŒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
            return same_frame_df.head(2)
    
    def display_products(self, products_df: pd.DataFrame):
        """ê²€ìƒ‰ëœ ì œí’ˆ ì •ë³´ ì¶œë ¥"""
        if products_df.empty:
            console.print("[yellow]ê²€ìƒ‰ëœ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤.[/yellow]")
            return
        
        table = Table(title="Sentinel-1 ê²€ìƒ‰ ê²°ê³¼ (ASF)")
        table.add_column("No.", style="cyan")
        table.add_column("ë‚ ì§œ", style="green")
        table.add_column("Path", style="yellow")
        table.add_column("Track", style="yellow")
        table.add_column("í¬ê¸° (MB)", style="magenta")
        table.add_column("ì œí’ˆëª…", style="blue")
        
        # Reset index to ensure sequential numbering
        for i, (idx, row) in enumerate(products_df.iterrows(), start=1):
            table.add_row(
                str(i),
                str(row['date'])[:10] if pd.notna(row['date']) else 'N/A',
                str(row.get('path', 'N/A')),
                str(row.get('track', 'N/A')),
                f"{row['size_mb']:.2f}",
                row['title'][:50] + "..." if len(row['title']) > 50 else row['title']
            )
        
        console.print(table)
    
    def download_products(
        self,
        products_df: pd.DataFrame,
        max_products: int = None
    ) -> List[str]:
        """ì œí’ˆ ë‹¤ìš´ë¡œë“œ
        
        Args:
            products_df: ë‹¤ìš´ë¡œë“œí•  ì œí’ˆ DataFrame
            max_products: ìµœëŒ€ ë‹¤ìš´ë¡œë“œ ê°œìˆ˜
        
        Returns:
            ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        if self.session is None:
            logger.error("ASF ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            logger.error("credentials.yamlì— ASF ì¸ì¦ ì •ë³´ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            return []
        
        download_dir = self.config.get_path('raw_data_dir')
        download_dir.mkdir(parents=True, exist_ok=True)
        
        if max_products:
            products_df = products_df.head(max_products)
        
        downloaded_files = []
        
        # Use enumerate for sequential numbering
        for i, (idx, row) in enumerate(products_df.iterrows(), start=1):
            logger.info(f"ë‹¤ìš´ë¡œë“œ ì¤‘ ({i}/{len(products_df)}): {row['title']}")
            
            try:
                product = row['product']
                
                # í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ ì¬í™•ì¸
                if 'EARTHDATA_USERNAME' not in os.environ:
                    credentials = self.config.get_credential('asf')
                    os.environ['EARTHDATA_USERNAME'] = str(credentials['username'])
                    os.environ['EARTHDATA_PASSWORD'] = str(credentials['password'])
                    logger.info("í™˜ê²½ ë³€ìˆ˜ ì¬ì„¤ì • ì™„ë£Œ")
                
                # ë‹¤ìš´ë¡œë“œ (ì„¸ì…˜ ì „ë‹¬)
                product.download(path=str(download_dir), session=self.session)
                
                # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ê²½ë¡œ ì¶”ì •
                file_path = download_dir / f"{row['title']}.zip"
                downloaded_files.append(str(file_path))
                logger.info(f"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {file_path}")
            except Exception as e:
                logger.error(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                logger.error(f"ìƒì„¸ ì˜¤ë¥˜ ì •ë³´: {type(e).__name__}")
                
                # ëŒ€ì•ˆ: wgetìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ URL ì•ˆë‚´
                if hasattr(product, 'properties'):
                    url = product.properties.get('url', '')
                    if url:
                        logger.info(f"ëŒ€ì•ˆ: ë‹¤ìŒ URLì—ì„œ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥")
                        logger.info(f"  {url}")
        
        return downloaded_files


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    console.print("[bold blue]Sentinel-1 ë°ì´í„° ê²€ìƒ‰ ì‹œì‘[/bold blue]")
    console.print("[yellow]ASF Data Searchë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.[/yellow]\n")
    
    try:
        retriever = Sentinel1Retriever()
        
        # ì œí’ˆ ê²€ìƒ‰
        products_df = retriever.search_products(
            start_date='2024-01-01',
            end_date='2024-01-31',
            max_results=10
        )
        
        # ê²°ê³¼ ì¶œë ¥
        retriever.display_products(products_df)
        
        if not products_df.empty:
            console.print("\n[yellow]ğŸ’¡ ë‹¤ìš´ë¡œë“œí•˜ë ¤ë©´ download_products() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.[/yellow]")
    
    except ImportError as e:
        console.print(f"[red]ì˜¤ë¥˜: {e}[/red]")
    except Exception as e:
        console.print(f"[red]ê²€ìƒ‰ ì‹¤íŒ¨: {e}[/red]")


if __name__ == "__main__":
    main()
